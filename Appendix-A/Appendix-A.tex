\chapter{Space-time skew-$t$ model}
\section{MCMC details} \label{sta:mcmc}
The MCMC sampling for the model in \sref{sts:hier} is done using {\tt R} (http://www.r-project.org). Whenever possible, we select conjugate priors (see \aref{sta:posterior}); however, for some of the parameters, no conjugate prior distributions exist.
For these parameters, we use a random walk Metropolis-Hastings update step.
In each Metropolis-Hastings update, we tune the algorithm during the burn-in period to give acceptance rates near 0.40.

\subsection*{Spatial knot locations}
For each day, we update the spatial knot locations, $\bw_1, \ldots, \bw_K$, using a Metropolis-Hastings block update.
Because the spatial domain is bounded, we generate candidate knots using the transformed knots $\bw^*_1, \ldots, \bw^*_K$ (see \sref{sts:temporal}) and a random walk bivariate Gaussian candidate distribution
\begin{align*}
  {\bw^*_k}^{(c)} \sim \text{N}({\bw^*_k}^{(r - 1)}, s^2 I_2)
\end{align*}
where ${\bw^*_k}^{(r - 1)}$ is the location for the transformed knot at MCMC iteration $r - 1$, $s$ is a tuning parameter, and $I_2$ is an identity matrix.
After candidates have been generated for all $K$ knots, the acceptance ratio is
\begin{align*}
  R = \left\{ \frac{ l[ Y_t(\bs | \bw_1^{(c)}, \ldots, \bw_K^{(c)}, \ldots)] }{l[ Y_t(\bs | \bw_1^{(r - 1)}, \ldots, \bw_K^{(r - 1)}, \ldots)]} \right\} \times \left\{ \frac{ \prod_{k = 1}^{K}\phi(\bw_k^{(c)})}{ \prod_{k = 1}^{K}\phi(\bw_k^{(r - 1)})} \right\} \times \left\{ \frac{ \prod_{k = 1}^{K} p({\bw^*_k}^{(c)})}{ \prod_{k = 1}^{K} p({\bw^*_k}^{(r - 1)})}\right\}
\end{align*}
where $l$ is the likelihood given in \eref{steq:hier}, and $p(\cdot)$ is the prior either taken from the time series given in \eref{sts:temporal} or assumed to be uniform over $\calD$.
The candidate knots are accepted with probability $\min\{R, 1\}$.

\subsection*{Spatial random effects}
If there is no temporal dependence amongst the observations, we use a Gibbs update for $z_{tk}$, and the posterior distribution is given in \aref{sta:posterior}.
If there is temporal dependence amongst the observations, then we update $z_{tk}$ using a Metropolis-Hastings update.
Because this model uses $|z_{tk}|$, we generate candidate random effects using the $z^*_{tk}$ (see \sref{sts:temporal}) and a random walk Gaussian candidate distribution
\begin{align*}
  {z^*_{tk}}^{(c)} \sim \text{N}({z^*_{tk}}^{(r - 1)}, s^2)
\end{align*}
where ${z^*_{tk}}^{(r-1)}$ is the value at MCMC iteration $r - 1$, and $s$ is a tuning parameter.
The acceptance ratio is
\begin{align*}
  R = \left\{ \frac{ l[Y_t(\bs) | z_{tk}^{(c)}, \ldots] }{ l[Y_t(\bs) | z_{tk}^{(r - 1)}]} \right\} \times \left\{ \frac{ p[ z_{tk}^{(c)} ] }{ p[ z_{tk}^{(r - 1)}]}\right\}
\end{align*}
where $p[\cdot]$ is the prior taken from the time series given in \sref{sts:temporal}.
The candidate is accepted with probability $\min\{R, 1\}$.

\subsection*{Variance terms}
When there is more than one site in a partition, then we update $\sigma^2_{tk}$ using a Metropolis-Hastings update.
First, we generate a candidate for $\sigma^2_{tk}$ using an IG$(a^*/s, b^*/s)$ candidate distribution in an independence Metropolis-Hastings update where $a^* = (n_{tk} + 1) / 2 + a$, $b^* = [Y_{tk}^\prime \Sigma^{-1}_{tk} Y_{tk} + z_{tk}^2] / 2 + b$, $n_{tk}$ is the number of sites in partition $k$ on day $t$, and $Y_{tk}$ and $\Sigma^{-1}_{tk}$ are the observations and precision matrix for partition $k$ on day $t$.
The acceptance ratio is
\begin{align*}
  R = \left\{
    \frac{ l[Y_t(\bs) | {\sigma^2_{tk}}^{(c)}, \ldots] }
         { l[Y_t(\bs) | {\sigma^2_{tk}}^{(r - 1)}]}
    \right\} \times \left\{
    \frac{ l[z_{tk} | {\sigma^2_{tk}}^{(c)}, \ldots] }
         { l[z_{tk} | {\sigma^2_{tk}}^{(r - 1)}, \ldots] }
    \right\} \times \left\{
    \frac{ p[ {\sigma^2_{tk}}^{(c)} ] }
         { p[ {\sigma^2_{tk}}^{(r - 1)}] }
    \right\} \times \left\{
    \frac{ c[ {\sigma^2_{tk}}^{(r - 1)}] }
         { c[ {\sigma^2_{tk}}^{(c)}]}
    \right\}
\end{align*}
where $p[\cdot]$ is the prior either taken from the time series given in \sref{sts:temporal} or assumed to be IG$(a, b)$, and $c[\cdot]$ is the candidate distribution.
The candidate is accepted with probability $\min\{R, 1\}$.

\subsection*{Spatial covariance parameters}
We update the three spatial covariance parameters, $\log(\rho)$, $\log(\nu)$, $\gamma$, using a Metropolis-Hastings block update step.
First, we generate a candidate using a random walk Gaussian candidate distribution
\begin{align*}
  \log(\rho)^{(c)} \sim \text{N}(\log(\rho)^{(r - 1)}, s^2)
\end{align*}
where $\log(\rho)^{(r-1)}$ is the value at MCMC iteration $r - 1$, and $s$ is a tuning parameter.
Candidates are generated for $\log(\nu)$ and $\gamma$ in a similar fashion.
The acceptance ratio is
\begin{align*}
  R = \left\{ \frac{ \prod_{t = 1}^{T} l[Y_t(\bs) | \rho^{(c)}, \nu^{(c)}, \gamma^{(c)}, \ldots] }{\prod_{t = 1}^{T} l[Y_t(\bs) | \rho^{(r-1)}, \nu^{(r-1)}, \gamma^{(r-1)}, \ldots] } \right\} \times \left\{ \frac{ p[\rho^{(c)}] }{ p[\rho^{(r - 1)] } } \right\} \times \left\{ \frac{ p[\nu^{(c)}] }{ p[\nu^{(r - 1)}] } \right\} \times \left\{ \frac{ p[ \gamma^{(c)} ] }{ p[\gamma^{(r - 1)} ] } \right\}.
\end{align*}
All three candidates are accepted with probability $\min\{R, 1\}$.

\section{Posterior distributions} \label{sta:posterior}

\subsection*{Conditional posterior of $z_{tk} \mid \ldots $}\label{sts:mvcondu}
If knots are independent over days, then the conditional posterior distribution of $|z_{tk}|$ is conjugate.
For simplicity, drop the subscript $t$, let $\tilde{z}_{tk} = |z_{tk}|$, and define
\begin{align*}
R(\bs) = \left\{
    \begin{array}{ll}
        Y(\bs) - X(\bs) \beta &s \in P_l\\[1em]
        Y(\bs) - X(\bs) \beta - \lambda \tilde{z}(\bs) \qquad & s \notin P_l
    \end{array}
\right.
\end{align*}
Let
\begin{align*}
    R_1 &= \text{the vector of } R(\bs) \text{ for } s \in P_l \\
    R_2 &= \text{the vector of } R(\bs) \text{ for } s \notin P_l \\
    \Omega &= \Sigma^{-1}.
\end{align*}
Then
\begin{align*}
    \pi(z_l | \ldots) &\propto \exp \left\{ -\frac{ 1 }{ 2 } \left[
        \left( \begin{array}{c}
            R_1 - \lambda \tilde{z}_l \bOne\\
            R_2
        \end{array} \right)^\prime
        \left( \begin{array}{cc}
            \Omega_{11} & \Omega_{12}\\
            \Omega_{21} & \Omega_{22}
        \end{array} \right)
        \left( \begin{array}{c}
            R_1 - \lambda \tilde{z}_l \bOne\\
            R_2
        \end{array} \right)
        +  \frac{ {\tilde{z}_l}^2 }{ \sigma_l^2 }\right]
    \right\} I(z_l > 0) \\
        &\propto \exp \left\{ -\frac{ 1 }{ 2 } \left[ \Lambda_l {\tilde{z}_l}^2 - 2 \mu_l \tilde{z}_l \right] \right\}
\end{align*}
where
\begin{align*}
    \mu_l &= \lambda ( R_1^\prime \Omega_{11} + R_2^\prime \Omega_{21} )\bOne\\
    \Lambda_l &= \lambda^2 \bOne^\prime \Omega_{11} \bOne + \frac{ 1 }{ \sigma^2_l }.
\end{align*}
Then $\tilde{Z}_l | \ldots \sim N_{(0, \infty)} (\Lambda_l^{-1} \mu_l, \Lambda_l^{-1})$

\subsection*{Conditional posterior of $\beta \mid \ldots$}\label{sts:betapost}
Let $\beta \sim \mbox{N}_{p}(0, \Lambda_0)$ where $\Lambda_0$ is a precision matrix. Then
\begin{align*}
    \pi(\beta \mid \ldots) & \propto \exp \left\{ - \frac{ 1 }{ 2 } \beta^\prime \Lambda_0 \beta - \frac{ 1 }{ 2 } \sum_{t = 1 }^m \left[\bY_t - \bX_t \beta - \lambda |z_t| \right]^\prime \Omega \left[\bY_t - \bX_t \beta - \lambda |z_t|\right] \right\}\\
     & \propto \exp \left\{ -\frac{ 1 }{ 2 } \left[ \beta^\prime \Lambda_\beta \beta  - 2 \sum_{ t = 1 }^\prime [ \beta^\prime X_t^\prime \Omega (\bY_t - \lambda |z_t| )] \right] \right\}\\
     & \propto \mbox{N} ( \Lambda_\beta^{-1} \mu_\beta , \Lambda_\beta^{-1})
\end{align*}
where
\begin{align*}
    \mu_\beta &= \sum_{t=1}^{T} \left[ X_t^\prime \Omega (\bY_t - \lambda |z_t|) \right]\\
    \Lambda_\beta &= \Lambda_0 + \sum_{ t = 1 }^{ T} X_t^\prime \Omega X_t.
\end{align*}

\subsection*{Conditional posterior of $\sigma^2 \mid \ldots$}\label{sts:sigpost}
In the case where $L = 1$ and temporal dependence is negligible, then $\sigma^2$ has a conjugate posterior distribution.
Let $\sigma_t^2 \iid \mbox{IG}(\alpha_0, \beta_0)$. For simplicity, drop the subscript $t$. Then
\begin{align*}
    \pi(\sigma^2 \mid \ldots) & \propto (\sigma^2)^{ -\alpha_0 - 1 / 2 - n / 2 - 1} \exp \left\{ -\frac{\beta_0}{\sigma^2} - \frac{ |z|^2 }{2 \sigma^2} - \frac{ (\bY - \bmu)^\prime \Sigma^{-1} (\bY - \bmu) }{2 \sigma^2} \right\} \\
    & \propto (\sigma^2)^{ -\alpha_0 - 1 / 2 - n / 2 - 1} \exp \left\{ - \frac{ 1 }{ \sigma^2 } \left[\beta_0 + \frac{ |z|^2 }{ 2 } + \frac{ 1 }{ 2 } (\bY - \bmu)^\prime \Sigma^{-1} (\bY - \mu) \right] \right\} \\
    & \propto \mbox{IG} (\alpha^*, \beta^*)
\end{align*}
where
\begin{align*}
    \alpha^* &= \alpha_0 + \frac{1}{2} + \frac{n}{2} \\
    \beta^* &= \beta_0 + \frac{ |z|^2 }{ 2 } + \frac{ 1 }{ 2 }(\bY - \bmu)^\prime \Sigma^{-1} (\bY - \bmu).
\end{align*}
In the case that $L > 1$, a random walk Metropolis Hastings step will be used to update $\sigma^2_{lt}$.

\subsection*{Conditional posterior of $\lambda \mid \ldots$}\label{sts:lambdapost}
For convergence purposes we model $\lambda = \lambda_1 \lambda_2$ where
\begin{align}
  \lambda_1 &= \left\{ \begin{array}{ll}
      +1 \quad & \text{w.p.} 0.5\\
      -1 \quad & \text{w.p.} 0.5
   \end{array}\right.\\
   \lambda^2_2 & \sim IG(\alpha_\lambda, \beta_\lambda).\\
\end{align}
Then
\begin{align*}
  \pi(\lambda_2 \mid \ldots) &\propto {\lambda_2^2}^{(-\alpha_\lambda - 1)} \exp\left\{ - \frac{ \beta_\lambda }{ \lambda_2^2} \right\} \prod_{t = 1}^{T} \prod_{k = 1}^K \frac{1} {\lambda_2} \exp\left\{ - \frac{ z^2_{tk} }{ 2 \lambda_2^2  \sigma_{tk})^2} \right\} \\
   & \propto {\lambda_2^2}^{(-\alpha_\lambda - kt - 1)} \exp \left\{ -\frac{1}{\lambda^2_2} \left[ \beta_\lambda + \frac{ z^2 }{2 \sigma^2_{tk}} \right] \right\}
\end{align*}
Then $\lambda_2 \mid \ldots \sim IG \left(\alpha_\lambda + kt, \beta_\lambda + \frac{ z^2 }{2 \sigma^2_{tk}} \right)$

\section{Proof that $\lim_{h \rightarrow \infty} \pi(h) = 0$} \label{sta:proofsamepartition}
Let $c$ be the midpoint of $\bs_1$ and $\bs_2$.
Define $A$ as the circle centered at $c$ with radius $h / 2$ where $h = ||\bs_1 - \bs_2||$ is the distance between sites $\bs_1$ and $\bs_2$.
Consider a homogeneous spatial Poisson process over $A$ with intensity given by
\begin{align*}
  \mu(A) = \lambda_{PP} |A| = \lambda_{PP} \pi \left(\frac{h}{2}\right)^2 = \lambda_{PPA}^* h^2.
\end{align*}
Consider a partition of $A$ into four regions, $B_1$, $B_2$, $R_1$, $R_2$ as seen in \fref{stfig:hpp}.
\begin{figure}
  \includegraphics[width=\linewidth]{plots/circles}
  \caption{Illustration of the partition of $A$.}
  \label{stfig:hpp}
\end{figure}
Let $N_j$ be the number of knots in $B_j, j = 1, 2$.
Then
\begin{align}
  P(\bs_1 \in P_i, \bs_2 \in P_{j \neq i}) \ge P(N_1 > 0, N_2 > 0)
\end{align}
since knots in both $B_1$ and $B_2$ is sufficient, but not necessary, to ensure that $\bs_1$ and $\bs_2$ are in different partition sets.
By definition of a Poission process, $N_1$ and $N_2$ are independent and thus $P(N_1 > 0, N_2 > 0) = P(N_1 > 0)^2$, and the intensity measure over $B_1$ is given by
\begin{align}
  \mu(B_1) &= \lambda_{PP} |B_1| = \lambda_{PP} \frac{h^2}{4} \left(\frac{2 \pi}{3} - \frac{\sqrt{3}}{2} \right) \nonumber \\
       &= \lambda^*_{PPB1} h^2.
\end{align}
So,
\begin{align}
  P(\bs_1 \in P_i, \bs_2 \in P_{j \neq i}) >= P(N_1 > 0)^2 = [1 - P(N_1 = 0)]^2 = [1 - \exp\left(-\lambda^*_{PPB1} h^2\right)]^2
\end{align}
which goes to 1 as $h$ goes to infinity.

%Then $\bs_1$ and $\bs_2$ are in different partitions almost surely if two or more points are in $A$.
%Let $N(A)$ be the number of points in $A$, and let
%\begin{align*}
%  \mu(A) = \lambda_{PP} |A| = \lambda_{PP} \pi \left(\frac{h}{2}\right)^2 = \lambda_{PP}^* h^2.
%\end{align*}

%
%
%Then
%\begin{align*}
%  P[N(A) \ge 2] &= 1 - P[N(A) = 0] - P[N(A) = 1]\\
%                &= 1 - \exp\{-\lambda h^2\} - \lambda h^2 \exp\{-\lambda h^2\} \\
%                &= 1 - (1 + \lambda h^2) \exp\{-\lambda h^2\}
%\end{align*}
%which goes to one as $h \rightarrow \infty$.


% Let $N(A)$ be the number of knots in $A$.
% So,
% \begin{align*}
%   P[ N(A) = k] = \frac{ \mu(A)^k \exp\{ -\mu(A)\}}{k!}.
% \end{align*}
% Then for any finite $k$, $\lim_{h \rightarrow \infty} P[N(A) = k] = 0$ because $\lim_{h \rightarrow \infty} \mu(A) = \infty$.
% With each additional knot in $A$, the chance that $\bs_1$ and $\bs_2$ will be be in the same partition will decrease, because partition membership is defined by the closest knot to a site.
% Therefore, $\lim_{h \rightarrow \infty} \pi(h) = 0$.

% \subsection{Half-normal distribution}
% Let $u = |z|$ where $Z \sim N(\mu, \sigma^2)$.
% Specifically, we consider the case where $\mu = 0$. Then $U$ follows a half-normal distribution which we denote as $U \sim HN(0, 1)$, and the density is given by
% \begin{align}
%   f_U(u) = \frac{ \sqrt{2} }{ \sqrt{\pi \sigma^2} } \exp \left( - \frac{ u^2 }{ 2 \sigma^2 } \right) I(u > 0)
% \end{align}
% When $\mu = 0$, the half-normal distribution is also equivalent to a $N_{(0, \infty)}(0, \sigma^2)$ where $N_{(a, b)}(\mu, \sigma^2)$ represents a normal distribution with mean $\mu$ and standard deviation $\sigma$ that has been truncated below at $a$ and above at $b$.

\section{Skew-$t$ distribution} \label{sta:skewt}
\subsection*{Univariate skew-$t$ distribution}
We say that $Y$ follows a univariate extended skew-$t$ distribution with location $\xi \in \calR$, scale $\omega > 0$, skew parameter $\alpha \in \calR$, and degrees of freedom $\nu$ if has distribution function
\begin{align}
  f_{\text{EST}}(y) = 2 f_T (z; \nu) F_T\left[ \alpha z \sqrt{ \frac{ \nu + 1 }{ \nu + z^2}}; \nu + 1 \right]
\end{align}
where $f_T(t; \nu)$ is a univariate Student's $t$ with $\nu$ degrees of freedom, $F_T(t; \nu) = P(T < t)$, and \hbox{$z = (y - \xi) / \omega$}.

\subsection*{Multivariate skew-$t$ distribution}
If $\bZ \sim \text{ST}_d(0, \bar{\bOmega}, \balpha, \eta)$ is a $d$-dimensional skew-$t$ distribution, and $\bY = \xi + \bomega \bZ$, where $\bomega = \text{diag}(\omega_1, \ldots, \omega_d)$, then the density of $Y$ at $y$ is
\begin{align}
  f_y(\by) = det(\bomega)^{-1} f_z(\bz)
\end{align}
where
\begin{align}
  f_z(\bz) &= 2 t_d(\bz; \bar{\bOmega}, \eta) T \left[ \balpha^\prime \bz \sqrt{ \frac{\eta + d}{\nu + Q(\bz)} }; \eta + d\right] \\
  \bz &= \bomega^{-1}(\by - \xi)
\end{align}
where $t_d(\bz; \bar{\bOmega}, \eta)$ is a $d$-dimensional Student's $t$-distribution with scale matrix $\bar{\bOmega}$ and degrees of freedom $\eta$, $Q(z) = \bz^\prime \bar{\Omega}^{-1}\bz$ and $T(\cdot; \eta)$ denotes the univariate Student's $t$ distribution function with $\eta$ degrees of freedom \citep{Azzalini2014}.

\subsection*{Extremal dependence}
For a bivariate skew-$t$ random variable $\bY = [Y(\bs), Y(\bt)]^\prime$, the $\chi(h)$ statistic \citep{Padoan2011} is given by
\begin{align} \label{steq:chiskew-t}
  \chi(h) = \bar{F}_{\text{EST}}\left\{ \frac{[x_1^{1 / \eta} - \varrho(h)] \sqrt{\eta + 1} }{\sqrt{1 - \varrho(h)^2}}; 0, 1, \alpha_1, \tau_1, \eta + 1 \right\} + \bar{F}_{\text{EST}}\left\{ \frac{ [x_2^{1 / \eta} - \varrho(h)] \sqrt{\eta + 1} }{ \sqrt{1 - \varrho(h)^2} }; 0, 1, \alpha_2, \tau_2, \eta + 1 \right\},
\end{align}
where $\bar{F}_{\text{EST}}$ is the univariate survival extended skew-$t$ function with zero location and unit scale, \hbox{$\varrho(h) = \text{cor}[y(\bs), y(\bt)]$}, $\alpha_j = \alpha_i \sqrt{1 - \varrho^2}$, $\tau_j = \sqrt{\eta + 1}(\alpha_j + \alpha_i \varrho)$, and $x_j = F_T(\bar{\alpha}_i \sqrt{\eta + 1}; 0, 1, \eta) / F_T(\bar{\alpha}_j \sqrt{\eta + 1}; 0, 1, \eta)$ with $j = 1, 2$ and $i = 2, 1$ and where $\bar{\alpha}_j = (\alpha_j + \alpha_i \varrho) / \sqrt{ 1 + \alpha_i^2 [1 - \varrho(h)^2]}$.

\subsection*{Proof that $\lim_{h \rightarrow \infty} \chi(h) > 0$}
Consider the bivariate distribution of $\bY = [Y(\bs), Y(\bt)]^\prime$, with $\varrho(h)$ given by \eref{steq:matern}.
So, $\lim_{h \rightarrow \infty} \varrho(h) = 0$.
Then
\begin{align}
  \lim_{h \rightarrow \infty} \chi(h) = \bar{F}_{\text{EST}}\left\{ \sqrt{\eta + 1}; 0, 1, \alpha_1, \tau_1, \eta + 1 \right\} + \bar{F}_{\text{EST}}\left\{ \sqrt{\eta + 1}; 0, 1, \alpha_2, \tau_2, \eta + 1 \right\}.
\end{align}
Because the extended skew-$t$ distribution is not bounded above, for all $\bar{F}_{\text{EST}}(x) = 1 - F_{\text{EST} (x)} > 0$ for all $x < \infty$.
Therefore, for a skew-$t$ distribution, $\lim_{h \rightarrow \infty} \chi(h) > 0$.

\section{Other parameterizations} \label{sta:otherparams}
Various forms of multivariate skew-normal and skew-$t$ distributions have been proposed in the literature.
In this section, we make a connection between our parameterization in \eref{steq:fullmodel} of the main text and another popular version.
\citet{Azzalini2014} and \citet{Beranger2016} define a skew-normal process as
\begin{align}
  \tilde{X}(\bs) = \tilde{\lambda}|z| + (1 - \tilde{\lambda}^2)^{1 / 2} v(\bs)
\end{align}
where $\tilde{\lambda} \in (-1, 1)$, $z ~ N(0, 1)$, $v(\bs)$ is a Gaussian process with mean zero, variance one, and spatial correlation function $\rho$.
To extend this to the skew-$t$ distribution, \citet{Azzalini2003} take $\tilde{Y}(\bs) = W\tilde{X}(\bs)$ where $W^{-2} \sim $ Gamma$(a / 2, a / 2)$.
Returning to the proposed parameterization, let $W^{-2} = \frac{2b}{a}\sigma^{-2} \sim$ Gamma$(a / 2, a / 2)$ so that \eref{steq:fullmodel} becomes
\begin{align}
  Y(\bs) = W \left[ \lambda \left(\frac{a}{2b}\right)^{1 / 2} |z| + \left(\frac{a}{2b}\right)^{1 / 2} v(\bs) \right].
\end{align}
Clearly setting $a = \nu / 2 > 0$, $b = \frac{\nu}{(1 - \tilde{\lambda}^2)} > 0$, and $\lambda = \tilde{\lambda} / (1 - \tilde{\lambda}^2)^{1 / 2} \in (-\infty, \infty)$ resolves the difference in parameterizations.
We note that our parameterization has three parameters $(a, b, \lambda)$ compared to the to parameters of the alternative parameterization $(a, \tilde{\lambda})$.
Since we have assumed that both $v(\bs)$ and $z$ have unit scale, the additional $b$ parameter in our parameterization controls the scale.
% However, if we introduce an overall scale parameter $c > 0$ into the alternative parameterization so that $\tilde{Y}(\bs) = c W \tilde{X}(\bs)$, then the two models remain equivalent by setting $a = \nu$, $b = \frac{\nu}{c^2 (1 - \tilde{\lambda}^2)}$, and $\lambda = \tilde{\lambda} / (1 - \tilde{\lambda}^2)^{1 / 2}$.

\section{Simulation study results} \label{sta:pdiffs}
The following tables show the methods that have significantly different Brier scores when using a Wilcoxon-Nemenyi-McDonald-Thompson test.
In each column, different letters signify that the methods have significantly different Brier scores.
For example, there is significant evidence to suggest that method 1 and method 4 have different Brier scores at $q(0.90)$, whereas there is not significant evidence to suggest that method 1 and method 2 have different Brier scores at $q(0.90)$.
In each table group A represents the group with the lowest Brier scores.
Groups are significant with a familywise error rate of $\alpha = 0.05$.

\begin{table}[htbp]
  \centering
  \caption{Setting 1 -- Gaussian marginal, $K = 1$ knot}
  \label{sttbl:gaussim}
  \begin{tabular}{|l|ccc|ccc|cccc|ccc|}
    \cline{2-14}
    \multicolumn{1}{c}{} & \multicolumn{3}{|c}{$q(0.90)$} & \multicolumn{3}{|c}{$q(0.95)$} & \multicolumn{4}{|c}{$q(0.98)$} & \multicolumn{3}{|c|}{$q(0.99)$} \\
    \hline
    Method 1 & A &   &   & A &   &   & A &   &   &   & A & B &   \\
    \hline
    Method 2 & A &   &   & A &   &   & A &   &   &   & A &   &   \\
    \hline
    Method 3 &   & B &   &   & B &   &   &   & C &   &   & B &   \\
    \hline
    Method 4 & A &   &   & A &   &   & A & B &   &   & A & B &   \\
    \hline
    Method 5 &   & B &   &   & B &   &   & B & C &   & A & B &   \\
    \hline
    Method 6 &   &   & C &   &   & C &   &   &   & D &   &   & C \\
    \hline
  \end{tabular}
\end{table}

% \begin{table}[htbp]
%   \centering
%   \caption{Setting 2: Symmetric-$t$ marginal, $K = 1$ knot}
%   \label{sttbl:t1k1sim}
%   \begin{tabular}{|l|cc|cccc|cccc|ccc|}
%     \cline{2-14}
%     \multicolumn{1}{c}{} & \multicolumn{2}{|c}{$q(0.90)$} & \multicolumn{4}{|c}{$q(0.95)$} & \multicolumn{4}{|c}{$q(0.98)$} & \multicolumn{3}{|c|}{$q(0.99)$} \\
%     \hline
%     Method 1 &   & B &   &   &   & D &   &   &   & D &   &   & C \\
%     \hline
%     Method 2 & A &   & A &   &   &   & A &   &   &   & A &   &   \\
%     \hline
%     Method 3 &   & B &   & B &   &   &   & B & C &   &   & B &   \\
%     \hline
%     Method 4 & A &   &   &   & C &   &   & B &   &   &   & B &   \\
%     \hline
%     Method 5 &   & B &   &   &   & D &   &   & C & D &   & B & C \\
%     \hline
%   \end{tabular}
% \end{table}

% \begin{table}[htbp]
%   \centering
%   \caption{Setting 3: Symmetric-$t$ marginal, $K = 5$ knots}
%   \label{sttbl:gaussim}
%   \begin{tabular}{|l|cc|cc|cc|cc|}
%     \cline{2-9}
%     \multicolumn{1}{c}{} & \multicolumn{2}{|c}{$q(0.90)$} & \multicolumn{2}{|c}{$q(0.95)$} & \multicolumn{2}{|c}{$q(0.98)$} & \multicolumn{2}{|c|}{$q(0.99)$} \\
%     \hline
%     Method 1 &   & B &   & B &   & B &   & B \\
%     \hline
%     Method 2 &   & B &   & B &   & B &   & B \\
%     \hline
%     Method 3 &   & B &   & B &   & B & A & B \\
%     \hline
%     Method 4 & A &   & A &   & A &   & A &   \\
%     \hline
%     Method 5 &   & B &   & B & A & B & A & B \\
%     \hline
%   \end{tabular}
% \end{table}

\begin{table}[htbp]
  \centering
  \caption{Setting 2 -- Skew-$t$ marginal, $K = 1$ knot}
  \label{sttbl:st1sim}
  \begin{tabular}{|l|ccccc|cccc|cccc|ccc|}
    \cline{2-17}
    \multicolumn{1}{c}{} & \multicolumn{5}{|c}{$q(0.90)$} & \multicolumn{4}{|c}{$q(0.95)$} & \multicolumn{4}{|c}{$q(0.98)$} & \multicolumn{3}{|c|}{$q(0.99)$} \\
    \hline
    Method 1 &   &   & C &   &   &   & B &   &   &   & B & C &   &   & B &   \\
    \hline
    Method 2 & A &   &   &   &   & A &   &   &   & A &   &   &   & A &   &   \\
    \hline
    Method 3 &   & B & C &   &   & A & B &   &   & A & B &   &   & A & B &   \\
    \hline
    Method 4 & A & B &   &   &   &   & B &   &   &   & B &   &   & A &   &   \\
    \hline
    Method 5 &   &   &   & D &   &   &   & C &   &   &   & C &   &   & B &   \\
    \hline
    Method 6 &   &   &   &   & E &   &   &   & D &   &   &   & D &   &   & C \\
    \hline
  \end{tabular}
\end{table}

\begin{table}[htbp]
  \centering
  \caption{Setting 3 -- Skew-$t$ marginal, $K = 5$ knots}
  \label{sttbl:st5sim}
  \begin{tabular}{|l|ccc|cccc|ccc|ccc|}
    \cline{2-14}
    \multicolumn{1}{c}{} & \multicolumn{3}{|c}{$q(0.90)$} & \multicolumn{4}{|c}{$q(0.95)$} & \multicolumn{3}{|c}{$q(0.98)$} & \multicolumn{3}{|c|}{$q(0.99)$} \\
    \hline
    Method 1 &   & B &   &   &   & C &   &   & B &   &   & B &   \\
    \hline
    Method 2 &   & B &   &   &   & C &   &   & B &   &   & B &   \\
    \hline
    Method 3 & A &   &   &   & B &   &   &   & B &   &   & B &   \\
    \hline
    Method 4 & A &   &   & A &   &   &   & A &   &   & A &   &   \\
    \hline
    Method 5 & A &   &   & A &   &   &   & A &   &   & A &   &   \\
    \hline
    Method 6 &   &   & C &   &   &   & D &   &   & C &   &   & C \\
    \hline
  \end{tabular}
\end{table}

\begin{table}[htbp]
  \centering
  \caption{Setting 4 -- Max-stable}
  \label{sttbl:mssim}
  \begin{tabular}{|l|cccc|cccc|ccc|ccc|}
    \cline{2-15}
    \multicolumn{1}{c}{} & \multicolumn{4}{|c}{$q(0.90)$} & \multicolumn{4}{|c}{$q(0.95)$} & \multicolumn{3}{|c}{$q(0.98)$} & \multicolumn{3}{|c|}{$q(0.99)$} \\
    \hline
    Method 1 & A & B &   &   &   & B &   &   &   & B &   &   &   & C \\
    \hline
    Method 2 &   & B &   &   &   & B & C &   &   & B &   &   & B & C \\
    \hline
    Method 3 &   &   & C & D &   &   & C &   &   & B &   &   & B &   \\
    \hline
    Method 4 &   &   &   & D &   &   &   & D &   &   & C &   &   & C \\
    \hline
    Method 5 &   &   & C &   &   &   & C &   &   & B &   &   & B & C \\
    \hline
    Method 6 & A &   &   &   & A &   &   &   & A &   &   & A &   &   \\
    \hline
  \end{tabular}
\end{table}

\begin{table}[htbp]
  \centering
  \caption{Setting 5 -- Transformation below $T = q(0.80)$}
  \label{sttbl:transsim}
  \begin{tabular}{|l|cccc|ccc|cccc|cccc|}
    \cline{2-16}
    \multicolumn{1}{c}{} & \multicolumn{4}{|c}{$q(0.90)$} & \multicolumn{3}{|c}{$q(0.95)$} & \multicolumn{4}{|c}{$q(0.98)$} & \multicolumn{4}{|c|}{$q(0.99)$} \\
    \hline
    Method 1 &   &   & C &   &   & B &   &   &   & C &   &   &   & C &   \\
    \hline
    Method 2 &   & B &   &   &   & B &   &   & B &   &   & A & B &   &   \\
    \hline
    Method 3 & A &   &   &   & A &   &   & A &   &   &   & A &   &   &   \\
    \hline
    Method 4 &   & B & C &   &   & B &   &   & B &   &   &   & B & C &   \\
    \hline
    Method 5 &   & B &   &   &   & B &   &   & B & C &   &   &   & C &   \\
    \hline
    Method 6 &   &   &   & D &   &   & C &   &   &   & D &   &   &   & D \\
    \hline
  \end{tabular}
\end{table}